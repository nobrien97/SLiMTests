# Randomised starting conditions for new motifs

The experiments so far have shown us that the more complex motifs can be under strong constraint due to ruggedness on the fitness landscape. When randomising the contributions of traits to fitness, we found that the only FFBH models which adapted were those where only 3 or fewer traits had strong contributions to fitness. This suggests a cost of complexity to these models.

So how do these complex models traverse the fitness landscape? To understand this, we need to simulate evolution from a range of different starting conditions, in a similar manner to the ruggedness test. We do this by randomly sampling a mutation for each molecular component and applying it as a fixation at the start of the simulation.

Then from these simulations we can measure the populations that do adapt and see if there are any similarities between them. What does the fitness landscape look like around their walks? The nature of epistasis and additive variance in molecular components? Distributions of effect sizes?

Each model has its own fitness landscape in this approach, since starting points are randomised and optima are relative to the starting point. Does this mean that replicates are comparable? There is the same proportional optimum shift per model, but this is on the trait scale, not necessarily on a genetic/fitness scale since these functions are non-linear. This means the average walk represents the behaviour of the motif's effect on adaptation/variance rather than the starting conditions. The average still makes sense, but comparing two individual walks becomes tricky. A difference or variance in responses between replicates would measure the variability in walks associated with the fitness landscape and mutation sampling, rather than just sampling. I think this is still fine, but needs to be mentioned in the chapter. 

A problem I faced implementing this is the fitness holes we saw: many combinations of parameters do not lead to a viable trait value (e.g. no steady state being reached). So a truly random search becomes very tricky. One way around this might be to randomly sample until we find a trait value that works. This seems to work fine, incurs a bit of a cost for FFBH (a few seconds to generate a valid combination), not really noticeable for other models. This does mean we might end up sampling a smaller range of the fitness landscape than otherwise or bias the search to a certain area, but we are doing this anyway when sampling molecular component values (e.g. a max sample size). 